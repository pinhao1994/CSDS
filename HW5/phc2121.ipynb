{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = sc.wholeTextFiles(\"input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'file:/home/vagrant/csds-material/input/file2',\n",
       "  u'Hello Hadoop Goodbye Hadoop\\n'),\n",
       " (u'file:/home/vagrant/csds-material/input/file1', u'Hello World Bye World\\n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = files.flatMapValues(lambda l: l.strip().split(\" \"))\n",
    "counts = words.mapValues(lambda w: (w, 1))\n",
    "results = sc.parallelize(counts.values().collect()).reduceByKey(lambda x, y : x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World: 2\n",
      "Bye: 1\n",
      "Hello: 2\n",
      "Goodbye: 1\n",
      "Hadoop: 2\n"
     ]
    }
   ],
   "source": [
    "for res in results.collect():\n",
    "    print(\"%s: %d\" % (res[0], res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import SQLContext and data types\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# sc is an existing SparkContext.\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Load a text file and convert each line to a tuple.\n",
    "lines = sc.textFile(\"hive/purchases.txt\")\n",
    "parts = lines.map(lambda l: l.split(\",\"))\n",
    "logs = parts.map(lambda p: (p[0], p[1], p[2], float(p[3]), p[4].strip()))\n",
    "\n",
    "# The schema is encoded in a string.\n",
    "schemaString = \"timestamp location category price card\"\n",
    "\n",
    "fields = [StructField(field_name, StringType(), True) \n",
    "          if field_name != \"price\" else StructField(field_name, FloatType(), True) \n",
    "          for field_name in schemaString.split()]\n",
    "schema = StructType(fields)\n",
    "\n",
    "# Apply the schema to the RDD.\n",
    "schemaLogs = sqlContext.createDataFrame(logs, schema)\n",
    "\n",
    "# Register the DataFrame as a table.\n",
    "schemaLogs.registerTempTable(\"purchases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the average price of the products that were purchased via Mastercard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg_price=275.0677317417774)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sqlContext.sql(\"SELECT AVG(price) as avg_price FROM purchases WHERE card='MasterCard'\")\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which date recorded the highest total sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(date=u'2012-03-17', total=2384.480026245117)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sqlContext.sql(\n",
    "    \"SELECT CAST(CAST(CAST(timestamp AS TIMESTAMP) AS DATE) AS STRING) as date, sum(price) as total \"+\n",
    "    \"FROM purchases GROUP BY CAST(CAST(CAST(timestamp AS TIMESTAMP) AS DATE) AS STRING) Order BY total DESC LIMIT 1\")\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the minimum value of a product under the Computers category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(price=0.3799999952316284)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sqlContext.sql(\"SELECT price FROM purchases WHERE category='Computers' ORDER BY price LIMIT 1\")\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many distinct categories of products are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Num_Category=18)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sqlContext.sql(\"SELECT COUNT(DISTINCT category) as Num_Category FROM purchases\")\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which store location had the lowest total sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(location=u'Plano', total=784.9599838256836)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sqlContext.sql(\"SELECT location, SUM(price) as total FROM purchases GROUP BY location ORDER BY total LIMIT 1\")\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp           location       category  price  card      \n",
      "2012-07-20 09:59:00 Corpus Christi CDs       327.91 Cash      \n",
      "2012-03-11 17:29:00 Durham         Books     115.09 Discover  \n",
      "2012-07-31 11:43:00 Rochester      Toys      332.07 MasterCard\n",
      "2012-06-18 14:47:00 Garland        Computers 31.99  Visa      \n",
      "2012-03-27 11:40:00 Tulsa          CDs       452.18 Discover  \n"
     ]
    }
   ],
   "source": [
    "purchasesDF = logs.toDF([\"timestamp\", \"location\", \"category\", \"price\", \"card\"])\n",
    "purchasesDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG(price)        \n",
      "275.06773195876286\n"
     ]
    }
   ],
   "source": [
    "# SELECT AVG(price) as avg_price FROM purchases WHERE card='MasterCard'\n",
    "purchasesDF\\\n",
    "    .filter(purchasesDF.card == 'MasterCard')\\\n",
    "    .agg(avg(col('price')))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date       total             \n",
      "2012-03-17 2384.4800000000005\n"
     ]
    }
   ],
   "source": [
    "# SELECT CAST(CAST(CAST(timestamp AS TIMESTAMP) AS DATE) AS STRING) as date, sum(price) as total \n",
    "# FROM purchases GROUP BY CAST(CAST(CAST(timestamp AS TIMESTAMP) AS DATE) AS STRING) Order BY total DESC LIMIT 1\n",
    "\n",
    "purchasesDF\\\n",
    "    .withColumn('date', purchasesDF['timestamp'].cast('timestamp').cast('date'))\\\n",
    "    .groupBy('date')\\\n",
    "    .agg(col('date'), sum(col('price')).alias('total'))\\\n",
    "    .sort(col('total').desc())\\\n",
    "    .show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price\n",
      "0.38 \n"
     ]
    }
   ],
   "source": [
    "# SELECT price FROM purchases WHERE category='Computers' ORDER BY price LIMIT 1\n",
    "purchasesDF\\\n",
    "    .filter(purchasesDF.category == 'Computers')\\\n",
    "    .sort('price')\\\n",
    "    .select('price')\\\n",
    "    .show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18L"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT COUNT(DISTINCT category) as Num_Category FROM purchases\n",
    "purchasesDF\\\n",
    "    .select('category')\\\n",
    "    .distinct()\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location total \n",
      "Plano    784.96\n"
     ]
    }
   ],
   "source": [
    "# SELECT location, SUM(price) as total FROM purchases GROUP BY location ORDER BY total LIMIT 1\n",
    "purchasesDF\\\n",
    "    .groupBy('location')\\\n",
    "    .agg(col('location'), sum(col('price')).alias('total'))\\\n",
    "    .sort('total')\\\n",
    "    .show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
